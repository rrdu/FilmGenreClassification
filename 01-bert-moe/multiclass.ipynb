{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4dedd46",
   "metadata": {},
   "source": [
    "# SBERT Encoder w/ MLP MoE for Multiclass Film Genre Classification\n",
    "\n",
    "Short test poses a unique challenge for many NLP models due to limited context length while retaining the difficulties of the nuances of structured languages. This model aims to use several methods to address each of these concerns individually. First, a trained autoencoder, SBERT, will be used to create a new hidden representation for the short text input sequences. Then for the diverse classification tasks several expert models will be trained to selectively specialize in specific genre embeddings. Simple MLP models are sufficient for mapping the smaller embeddings to output classes while keeping the full model simple to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2b21aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch.callbacks import BaseFinetuning\n",
    "from torchmetrics.classification import MultilabelF1Score\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787d36dc",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e5570ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Expert(nn.Module):\n",
    "    \"\"\"\n",
    "    A simple Feed-Forward Network acting as a single 'Expert'.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class TopKRouter(nn.Module):\n",
    "    \"\"\"\n",
    "    Gating Network that selects the top-k experts for each input.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, num_experts, top_k=2):\n",
    "        super().__init__()\n",
    "        self.gate = nn.Linear(input_dim, num_experts)\n",
    "        self.top_k = top_k\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.gate(x)\n",
    "        top_k_vals, top_k_indices = torch.topk(logits, self.top_k, dim=1)\n",
    "        router_probs = F.softmax(top_k_vals, dim=1)\n",
    "        return router_probs, top_k_indices, logits\n",
    "\n",
    "class MoEClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    The Mixture of Experts Classification Head.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, num_classes, num_experts=4, top_k=2, expert_hidden_dim=128):\n",
    "        super().__init__()\n",
    "        self.num_experts = num_experts\n",
    "        self.top_k = top_k\n",
    "        \n",
    "        self.router = TopKRouter(input_dim, num_experts, top_k=top_k)\n",
    "        self.experts = nn.ModuleList([\n",
    "            Expert(input_dim, expert_hidden_dim, num_classes) \n",
    "            for _ in range(num_experts)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        router_probs, expert_indices, router_logits = self.router(x)\n",
    "        \n",
    "        final_output = torch.zeros(batch_size, self.experts[0].net[-1].out_features).to(x.device)\n",
    "        \n",
    "        for k in range(self.top_k):\n",
    "            selected_experts = expert_indices[:, k]\n",
    "            gate_weight = router_probs[:, k].unsqueeze(1)\n",
    "            \n",
    "            for expert_idx in range(self.num_experts):\n",
    "                mask = (selected_experts == expert_idx)\n",
    "                if mask.any():\n",
    "                    expert_input = x[mask]\n",
    "                    expert_output = self.experts[expert_idx](expert_input)\n",
    "                    final_output[mask] += gate_weight[mask] * expert_output\n",
    "                    \n",
    "        return final_output, router_logits\n",
    "\n",
    "class SBERT_MoE_Model(nn.Module):\n",
    "    \"\"\"\n",
    "    Full End-to-End Model: SBERT Encoder + MoE Classifier\n",
    "    \"\"\"\n",
    "    def __init__(self, model_name='all-MiniLM-L6-v2', num_classes=5, num_experts=8, top_k=2):\n",
    "        super().__init__()\n",
    "        # 1. Initialize SBERT\n",
    "        self.sbert = SentenceTransformer(model_name)\n",
    "        \n",
    "        # 2. Capture device choice\n",
    "        target_device = self.sbert.device \n",
    "        \n",
    "        # 3. Initialize MoE head\n",
    "        embedding_dim = self.sbert.get_sentence_embedding_dimension()\n",
    "        self.moe_head = MoEClassifier(\n",
    "            input_dim=embedding_dim,\n",
    "            num_classes=num_classes,\n",
    "            num_experts=num_experts,\n",
    "            top_k=top_k\n",
    "        )\n",
    "        \n",
    "        # 4. Force MoE head to same device\n",
    "        self.moe_head.to(target_device)\n",
    "\n",
    "    def forward(self, text_input):\n",
    "        # Encode and Detach to treat embeddings as fixed features initially\n",
    "        features = self.sbert.encode(text_input, convert_to_tensor=True)\n",
    "        \n",
    "        # Important: Clone and detach to avoid \"Inference Tensor\" errors during backprop\n",
    "        # If unfreezing later, the optimizer handles the graph connection, \n",
    "        # but for the initial forward pass logic, this is safe.\n",
    "        features = features.clone().detach() \n",
    "        \n",
    "        logits, router_logits = self.moe_head(features)\n",
    "        return logits, router_logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af1d544",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df84f6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.classification import MulticlassAccuracy\n",
    "\n",
    "class MoE_LightningModule(pl.LightningModule):\n",
    "    def __init__(self, model, num_classes, num_experts, learning_rate=1e-3, aux_loss_weight=0.01):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters(ignore=['model'])\n",
    "        \n",
    "        self.backbone = model.sbert\n",
    "        self.head = model.moe_head\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        # --- FIX 1: Store these for the loss calculation ---\n",
    "        self.num_experts = num_experts\n",
    "        self.aux_loss_weight = aux_loss_weight\n",
    "        \n",
    "        # Loss & Metric\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.val_acc = MulticlassAccuracy(num_classes=num_classes, average='micro')\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Standard forward pass\n",
    "        features = self.backbone.tokenize(x)\n",
    "        features = {k: v.to(self.device) for k, v in features.items()}\n",
    "        out = self.backbone(features)\n",
    "        embeddings = out['sentence_embedding']\n",
    "        return self.head(embeddings)\n",
    "\n",
    "    # --- FIX 2: Re-add the Load Balancing Logic ---\n",
    "    def _compute_load_balancing_loss(self, router_logits):\n",
    "        \"\"\"\n",
    "        Encourages the router to send equal traffic to all experts.\n",
    "        \"\"\"\n",
    "        # 1. Get probability of selecting each expert\n",
    "        probs = F.softmax(router_logits, dim=1) # [batch_size, num_experts]\n",
    "        \n",
    "        # 2. Mean probability per expert across the batch\n",
    "        mean_probs = probs.mean(dim=0) # [num_experts]\n",
    "        \n",
    "        # 3. Variance-like penalty (sum of squares)\n",
    "        # If traffic is perfectly even, this value is minimized.\n",
    "        aux_loss = (mean_probs ** 2).sum() * self.num_experts\n",
    "        \n",
    "        return aux_loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        texts, targets = batch\n",
    "        logits, router_logits = self(texts)\n",
    "        \n",
    "        # 1. Main Classification Loss\n",
    "        cls_loss = self.criterion(logits, targets)\n",
    "        \n",
    "        # --- FIX 3: Add Aux Loss to Total Loss ---\n",
    "        aux_loss = self._compute_load_balancing_loss(router_logits)\n",
    "        \n",
    "        total_loss = cls_loss + (self.aux_loss_weight * aux_loss)\n",
    "        \n",
    "        # Log both for debugging\n",
    "        self.log(\"train_loss\", total_loss)\n",
    "        self.log(\"train_cls_loss\", cls_loss)\n",
    "        self.log(\"train_aux_loss\", aux_loss)\n",
    "        \n",
    "        return total_loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        texts, targets = batch\n",
    "        logits, _ = self(texts)\n",
    "        loss = self.criterion(logits, targets)\n",
    "        self.val_acc(logits, targets)\n",
    "        \n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        self.log(\"val_acc\", self.val_acc, prog_bar=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(self.parameters(), lr=self.learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d26611c",
   "metadata": {},
   "source": [
    "## Movie Genre Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b590f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from imdb_arh_train.csv...\n",
      "Loading data from imdb_arh_val.csv...\n",
      "Loading data from imdb_arh_test.csv...\n",
      "--- Sanity Checks ---\n",
      "Num classes: 3\n",
      "First 5 classes: ['action', 'horror', 'romance']\n",
      "Train size: 67772\n",
      "Val size:   14523\n",
      "\n",
      "Sample Text Type: <class 'str'>\n",
      "Sample Label Type: <class 'torch.Tensor'>\n",
      "Sample Label Shape: torch.Size([])\n",
      "Sample Label Dtype: torch.int64\n",
      "\n",
      "--- DataLoader Batch Check ---\n",
      "Batch Text Length: 32\n",
      "Batch Label Shape: torch.Size([32])\n",
      "Shuffle is working (First elements differ).\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "class IMDBDataset(Dataset):\n",
    "    def __init__(self, data_dir_path, filename, class_names, text_col='description', label_col='csv_genre'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            label_col (str): Now defaults to 'csv_genre' (single label)\n",
    "        \"\"\"\n",
    "        self.data_path = Path(data_dir_path) / filename\n",
    "        \n",
    "        if not self.data_path.exists():\n",
    "            raise FileNotFoundError(f\"File not found at: {self.data_path.resolve()}\")\n",
    "            \n",
    "        print(f\"Loading data from {self.data_path.name}...\")\n",
    "        self.df = pd.read_csv(self.data_path)\n",
    "        \n",
    "        # 1. Process Text\n",
    "        self.texts = self.df[text_col].fillna(\"\").astype(str).tolist()\n",
    "        \n",
    "        # 2. Process Labels (Single Integer Encoding)\n",
    "        self.class_to_idx = {cls: i for i, cls in enumerate(class_names)}\n",
    "        self.labels = []\n",
    "        \n",
    "        unseen_genres = set()\n",
    "        \n",
    "        # Iterate directly over the column\n",
    "        for genre_raw in self.df[label_col]:\n",
    "            # Clean whitespace\n",
    "            genre_str = str(genre_raw).strip()\n",
    "            \n",
    "            if genre_str in self.class_to_idx:\n",
    "                # Store just the INTEGER index (e.g., 5)\n",
    "                self.labels.append(self.class_to_idx[genre_str])\n",
    "            else:\n",
    "                # Handle unknown classes (optional: map to -1 or a generic 'Other')\n",
    "                # For now, we'll just warn and append a dummy index (e.g., 0) \n",
    "                # or raise an error depending on your preference.\n",
    "                unseen_genres.add(genre_str)\n",
    "                self.labels.append(0) # Defaulting to class 0 (Risky, better to filter data first)\n",
    "\n",
    "        if unseen_genres:\n",
    "            print(f\"⚠️  WARNING: Found {len(unseen_genres)} labels not in class list.\")\n",
    "            print(f\"   Examples: {list(unseen_genres)[:5]}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # RETURN TYPE CHANGE:\n",
    "        # Torch expects LongTensor (int64) for CrossEntropyLoss targets\n",
    "        # We do NOT wrap it in a list. Just the scalar tensor.\n",
    "        label_tensor = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        \n",
    "        return self.texts[idx], label_tensor\n",
    "\n",
    "    @staticmethod\n",
    "    def discover_classes(data_dir_path, filename, label_col='csv_genre'):\n",
    "        \"\"\"\n",
    "        Scans for unique SINGLE categories.\n",
    "        \"\"\"\n",
    "        path = Path(data_dir_path) / filename\n",
    "        df = pd.read_csv(path)\n",
    "        \n",
    "        # No splitting or exploding needed for single-label\n",
    "        genres = df[label_col].dropna().astype(str).str.strip().unique()\n",
    "        \n",
    "        return sorted(list(genres))\n",
    "\n",
    "\n",
    "DATA_DIR = Path('../data/imdb_arh_trimmed')\n",
    "CLASS_NAMES = IMDBDataset.discover_classes(DATA_DIR, 'imdb_arh_train.csv')\n",
    "NUM_WORKERS = 4\n",
    "\n",
    "tr_ds = IMDBDataset(data_dir_path=DATA_DIR, filename='imdb_arh_train.csv', class_names=CLASS_NAMES)\n",
    "va_ds = IMDBDataset(data_dir_path=DATA_DIR, filename='imdb_arh_val.csv', class_names=CLASS_NAMES)\n",
    "te_ds = IMDBDataset(data_dir_path=DATA_DIR, filename='imdb_arh_test.csv', class_names=CLASS_NAMES)\n",
    "\n",
    "tr_loader = DataLoader(tr_ds, batch_size=32, num_workers=NUM_WORKERS, shuffle=True)\n",
    "va_loader = DataLoader(va_ds, batch_size=64, num_workers=NUM_WORKERS, shuffle=False)\n",
    "te_loader = DataLoader(te_ds, batch_size=64, num_workers=NUM_WORKERS, shuffle=False)\n",
    "\n",
    "print(\"--- Sanity Checks ---\")\n",
    "# 1. Check if classes were discovered\n",
    "print(f\"Num classes: {len(CLASS_NAMES)}\")\n",
    "print(f\"First 5 classes: {CLASS_NAMES[:5]}\")\n",
    "\n",
    "# 2. Check Dataset lengths\n",
    "print(f\"Train size: {len(tr_ds)}\")\n",
    "print(f\"Val size:   {len(va_ds)}\")\n",
    "\n",
    "# 3. Inspect a single sample\n",
    "sample_text, sample_label = tr_ds[0]\n",
    "\n",
    "print(f\"\\nSample Text Type: {type(sample_text)}\") # Should be <class 'str'>\n",
    "print(f\"Sample Label Type: {type(sample_label)}\") # Should be <class 'torch.Tensor'>\n",
    "print(f\"Sample Label Shape: {sample_label.shape}\") # Should be torch.Size([num_classes])\n",
    "print(f\"Sample Label Dtype: {sample_label.dtype}\") # Should be torch.float32\n",
    "\n",
    "print(\"\\n--- DataLoader Batch Check ---\")\n",
    "\n",
    "# Get one batch from the training loader\n",
    "batch_texts, batch_labels = next(iter(tr_loader))\n",
    "\n",
    "print(f\"Batch Text Length: {len(batch_texts)}\") # Should match batch_size (32)\n",
    "print(f\"Batch Label Shape: {batch_labels.shape}\") # Should be [32, num_classes]\n",
    "\n",
    "# Check if shuffling works (Compare first item of two different iterator calls)\n",
    "batch_texts_2, _ = next(iter(tr_loader))\n",
    "if batch_texts[0] != batch_texts_2[0]:\n",
    "    print(\"Shuffle is working (First elements differ).\")\n",
    "else:\n",
    "    print(\"Warning: Shuffle might not be working or dataset is very small.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2d9745",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/dodogama/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mconradli90\u001b[0m (\u001b[33mconradli90-duke-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20251121_230018-uick8bzj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/conradli90-duke-university/MovieGenreMulticlassMoE/runs/uick8bzj' target=\"_blank\">testrun</a></strong> to <a href='https://wandb.ai/conradli90-duke-university/MovieGenreMulticlassMoE' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/conradli90-duke-university/MovieGenreMulticlassMoE' target=\"_blank\">https://wandb.ai/conradli90-duke-university/MovieGenreMulticlassMoE</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/conradli90-duke-university/MovieGenreMulticlassMoE/runs/uick8bzj' target=\"_blank\">https://wandb.ai/conradli90-duke-university/MovieGenreMulticlassMoE/runs/uick8bzj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3060 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "/home/dodogama/anaconda3/envs/nlp-py310/lib/python3.10/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:751: Checkpoint directory /home/dodogama/code/FilmGenreClassification/01-bert-moe/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type                | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | backbone  | SentenceTransformer | 22.7 M | train\n",
      "1 | head      | MoEClassifier       | 500 K  | train\n",
      "2 | criterion | CrossEntropyLoss    | 0      | train\n",
      "3 | val_acc   | MulticlassAccuracy  | 0      | train\n",
      "----------------------------------------------------------\n",
      "23.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "23.2 M    Total params\n",
      "92.855    Total estimated model params size (MB)\n",
      "70        Modules in train mode\n",
      "120       Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Training ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "759262a263564703b0b1c6f644664f49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dodogama/anaconda3/envs/nlp-py310/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:527: Found 120 module(s) in eval mode at the start of training. This may lead to unexpected behavior during training. If this is intentional, you can ignore this warning.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58a2d8c6a7c240b2a9e83f6e0906cbb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de1fe3020ed841f9a93acd726e7008df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 1.093\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c24e7b7fdca04be1993a67e9d29aee6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.001 >= min_delta = 0.0. New best score: 1.092\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84862bbeaca94b2bb583d59644ef3c6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from lightning.pytorch.loggers import WandbLogger\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from dotenv import load_dotenv\n",
    "import wandb\n",
    "\n",
    "load_dotenv()\n",
    "wandb.login(key=os.getenv(\"WANDB_API_KEY\"))\n",
    "\n",
    "# Initialize Logger\n",
    "wandb_logger = WandbLogger(\n",
    "    project=\"MovieGenreMulticlassMoE\", \n",
    "    name=\"testrun\",\n",
    "    log_model=False,\n",
    ")\n",
    "wandb_logger.experiment.config.update({\"class_names\": CLASS_NAMES})\n",
    "\n",
    "# --- Initialize Models ---\n",
    "num_experts = 10\n",
    "num_classes = len(CLASS_NAMES)\n",
    "backbone = SBERT_MoE_Model(\n",
    "    num_classes=num_classes, \n",
    "    num_experts=num_experts, \n",
    "    top_k=2\n",
    ")\n",
    "\n",
    "# Wrap in Lightning\n",
    "pl_module = MoE_LightningModule(\n",
    "    model=backbone, \n",
    "    num_classes=num_classes, \n",
    "    num_experts=num_experts,\n",
    ")\n",
    "\n",
    "# Callback to stop training early\n",
    "early_stop_cb = EarlyStopping(\n",
    "    monitor=\"val_loss\",  # Watch the validation loss\n",
    "    min_delta=0.00,      # Minimum change to qualify as an improvement\n",
    "    patience=3,          # Stop if no improvement for 3 epochs in a row\n",
    "    verbose=True,\n",
    "    mode=\"min\"\n",
    ")\n",
    "\n",
    "# Callback to save best model based on validation loss\n",
    "checkpoint_cb = ModelCheckpoint(\n",
    "    dirpath=\"checkpoints/\",\n",
    "    filename=\"moe-film-{epoch:02d}-{val_loss:.2f}\",\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    save_top_k=1,\n",
    "    save_last=True\n",
    ")\n",
    "\n",
    "# --- Train ---\n",
    "print(\"--- Starting Training ---\")\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=20,\n",
    "    accelerator=\"auto\",\n",
    "    callbacks=[early_stop_cb, checkpoint_cb],\n",
    "    enable_progress_bar=True,\n",
    "    log_every_n_steps=1,\n",
    "    logger=wandb_logger\n",
    ")\n",
    "\n",
    "\n",
    "trainer.fit(\n",
    "    pl_module, \n",
    "    train_dataloaders=tr_loader, \n",
    "    val_dataloaders=va_loader,\n",
    ")\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ddd6c0",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca09386",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchmetrics import MetricCollection\n",
    "from torchmetrics.classification import MulticlassF1Score, MulticlassPrecision, MulticlassRecall, MulticlassAccuracy\n",
    "\n",
    "\n",
    "def map_logits_to_labels_multiclass(logits, class_names):\n",
    "    \"\"\"\n",
    "    Adapted for Multi-Class: Picks the single highest probability class.\n",
    "    \"\"\"\n",
    "    # 1. Softmax to get probabilities that sum to 1\n",
    "    probs = torch.softmax(logits, dim=1).cpu()\n",
    "    \n",
    "    # 2. Argmax to get the index of the winner\n",
    "    pred_indices = torch.argmax(probs, dim=1)\n",
    "    \n",
    "    # 3. Map indices to names\n",
    "    batch_results = [class_names[idx.item()] for idx in pred_indices]\n",
    "    \n",
    "    return batch_results, probs\n",
    "\n",
    "# A. Define Path\n",
    "CHECKPOINT_PATH = \"checkpoints/moe-film-epoch=04-val_loss=0.14.ckpt\" # Update this!\n",
    "\n",
    "# B. Re-initialize Architecture (Ensure num_classes matches your new dataset)\n",
    "num_experts = 10\n",
    "num_classes = len(CLASS_NAMES)\n",
    "backbone_skeleton = SBERT_MoE_Model(\n",
    "    num_classes=num_classes, \n",
    "    num_experts=num_experts, \n",
    "    top_k=2\n",
    ")\n",
    "\n",
    "# C. Load Weights\n",
    "print(f\"Loading model from: {CHECKPOINT_PATH}\")\n",
    "# Note: If you had to do the manual state_dict filtering discussed earlier, \n",
    "# load that specific model object here instead of using load_from_checkpoint.\n",
    "loaded_model = MoE_LightningModule.load_from_checkpoint(\n",
    "    CHECKPOINT_PATH,\n",
    "    model=backbone_skeleton,\n",
    "    num_classes=num_classes,\n",
    "    num_experts=num_experts,\n",
    ")\n",
    "\n",
    "# D. Prepare\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "loaded_model.to(device)\n",
    "loaded_model.eval()\n",
    "\n",
    "# ==========================================\n",
    "# 2. INITIALIZE GLOBAL METRICS (MULTICLASS)\n",
    "# ==========================================\n",
    "metrics = MetricCollection({\n",
    "    'accuracy': MulticlassAccuracy(num_classes=num_classes, average='micro'),\n",
    "    'f1': MulticlassF1Score(num_classes=num_classes, average='micro'),\n",
    "    'precision': MulticlassPrecision(num_classes=num_classes, average='micro'),\n",
    "    'recall': MulticlassRecall(num_classes=num_classes, average='micro')\n",
    "}).to(device)\n",
    "\n",
    "# ==========================================\n",
    "# 3. INFERENCE LOOP\n",
    "# ==========================================\n",
    "print(\"\\n--- Running Inference on Full Test Loader (Multi-Class) ---\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, batch in enumerate(te_loader):\n",
    "        \n",
    "        # Unpack: Labels are now 1D Integer Tensors (e.g., [5, 2, 0...])\n",
    "        texts, true_label_indices = batch\n",
    "        \n",
    "        # Move to device\n",
    "        true_label_indices = true_label_indices.to(device)\n",
    "        \n",
    "        # Forward Pass\n",
    "        logits, _ = loaded_model(texts)\n",
    "        \n",
    "        # --- A. ACCUMULATE METRICS ---\n",
    "        # Torchmetrics handles Logits vs Int Indices automatically\n",
    "        metrics.update(logits, true_label_indices)\n",
    "\n",
    "        # --- B. VISUALIZE ---\n",
    "        if batch_idx < 5: \n",
    "            # Map outputs\n",
    "            predicted_labels_batch, probs_batch = map_logits_to_labels_multiclass(logits, CLASS_NAMES)\n",
    "            \n",
    "            for i, (text, pred_lbl, probs) in enumerate(zip(texts, predicted_labels_batch, probs_batch)):\n",
    "                \n",
    "                # Decode Ground Truth (Simpler now: just look up the index)\n",
    "                true_idx = true_label_indices[i].item()\n",
    "                actual_lbl = CLASS_NAMES[true_idx]\n",
    "\n",
    "                # Print\n",
    "                print(f\"\\n[Batch {batch_idx} - Sample {i}]\")\n",
    "                print(f\"Input Text:    {text[:80]}...\") \n",
    "                print(f\"PREDICTED:     {pred_lbl}\")\n",
    "                print(f\"GROUND TRUTH:  {actual_lbl}\")\n",
    "                \n",
    "                # Show \"High Probs\" to see if the model was confused\n",
    "                # (e.g., showing if it was 51% Action vs 49% Adventure)\n",
    "                significant_probs = {CLASS_NAMES[j]: round(p, 3) for j, p in enumerate(probs.tolist()) if p > 0.1}\n",
    "                print(f\"High Probs:    {significant_probs}\")\n",
    "\n",
    "# ==========================================\n",
    "# 4. RESULTS\n",
    "# ==========================================\n",
    "print(\"\\n\" + \"=\"*30)\n",
    "print(\"FINAL EVALUATION REPORT (MULTICLASS)\")\n",
    "print(\"=\"*30)\n",
    "\n",
    "final_results = metrics.compute()\n",
    "\n",
    "for metric_name, value in final_results.items():\n",
    "    print(f\"Global {metric_name.capitalize()}: {value.item():.4f}\")\n",
    "\n",
    "metrics.reset()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
